name: manual_tests
version: "1.2.0"
summary: "Runs all manual hook/rule tests using sub-agents. Use when validating that DeepWork rules fire correctly."
description: |
  A workflow for running manual tests that validate DeepWork rules/hooks fire correctly.

  This job tests that rules fire when they should AND do not fire when they shouldn't.
  Each test is run in a SUB-AGENT (not the main agent) because:
  1. Sub-agents run in isolated contexts where file changes can be detected
  2. The Stop hook automatically evaluates rules when each sub-agent completes
  3. The main agent can observe whether hooks fired without triggering them manually

  CRITICAL: All tests MUST run in sub-agents. The main agent MUST NOT make the file
  edits itself - it spawns sub-agents to make edits, then observes whether the hooks
  fired automatically when those sub-agents returned.

  Steps:
  1. run_not_fire_tests - Run all "should NOT fire" tests in PARALLEL sub-agents
  2. run_fire_tests - Run all "should fire" tests in SERIAL sub-agents with reverts between

  Test types covered:
  - Trigger/Safety mode
  - Set mode (bidirectional)
  - Pair mode (directional)
  - Command action
  - Multi safety
  - Infinite block (prompt and command)
  - Created mode (new files only)

changelog:
  - version: "1.2.0"
    changes: "Added early termination on 2 test failures; emphasized mandatory file revert and queue clear after each step"
  - version: "1.1.0"
    changes: "Added rules queue clearing between tests to prevent anti-infinite-loop mechanism from blocking tests"
  - version: "1.0.0"
    changes: "Initial job creation - tests run in sub-agents to observe automatic hook firing"

steps:
  - id: run_not_fire_tests
    name: "Run Should-NOT-Fire Tests"
    description: "Runs all 'should NOT fire' tests in parallel sub-agents. Use to verify rules don't fire when safety conditions are met."
    instructions_file: steps/run_not_fire_tests.md
    inputs: []
    outputs:
      - not_fire_results  # implicit state: all "should NOT fire" tests passed
    dependencies: []
    quality_criteria:
      - "**Sub-Agents Used**: Did the main agent spawn sub-agents (using the Task tool) to make the file edits? The main agent must NOT edit the test files directly."
      - "**Parallel Execution**: Were multiple sub-agents launched in parallel (in a single message with multiple Task tool calls)?"
      - "**Hooks Observed**: Did the main agent observe that no blocking hooks fired when the sub-agents returned? The hooks fire AUTOMATICALLY - the agent must NOT manually run the rules_check command."
      - "**Early Termination**: If 2 tests failed, did testing halt immediately with results reported?"
      - "**Git Reverted**: Were changes reverted and queue cleared after tests completed (or after early termination) using `git checkout -- manual_tests/` and `rm -rf .deepwork/tmp/rules/queue/*.json`?"

  - id: run_fire_tests
    name: "Run Should-Fire Tests"
    description: "Runs all 'should fire' tests serially with git reverts between each. Use after NOT-fire tests to verify rules fire correctly."
    instructions_file: steps/run_fire_tests.md
    inputs:
      - file: not_fire_results
        from_step: run_not_fire_tests
    outputs:
      - fire_results  # implicit state: all "should fire" tests passed
    dependencies:
      - run_not_fire_tests
    quality_criteria:
      - "**Sub-Agents Used**: Did the main agent spawn a sub-agent (using the Task tool) for EACH test? The main agent must NOT edit the test files directly."
      - "**Serial Execution**: Were sub-agents launched ONE AT A TIME (not in parallel) to prevent cross-contamination?"
      - "**Hooks Fired Automatically**: Did the main agent observe the blocking hooks firing automatically when each sub-agent returned? The agent must NOT manually run the rules_check command."
      - "**Git Reverted Between Tests**: Was `git checkout -- manual_tests/` and `rm -rf .deepwork/tmp/rules/queue/*.json` run after each test to revert files and prevent cross-contamination?"
      - "**Early Termination**: If 2 tests failed, did testing halt immediately with results reported?"
      - "**Results Recorded**: Did the main agent track pass/fail status for each test case?"
